# LLaVA μ½”λ“λ² μ΄μ¤λ¥Ό μ‚¬μ©ν• λ©€ν‹°λ¨λ‹¬ λ€ν™”λ¥Ό μ„ν• InternVL

μ΄ ν΄λ”μ—λ” InternVL 1.0 λ…Όλ¬Έμ μ„Ήμ… 4.4μ— ν•΄λ‹Ήν•λ” InternVL-Chat V1.0μ κµ¬ν„μ΄ ν¬ν•¨λμ–΄ μμµλ‹λ‹¤.

μ΄ λ¶€λ¶„μ—μ„λ” μ£Όλ΅ LLaVA μ½”λ“λ² μ΄μ¤λ¥Ό μ‚¬μ©ν•μ—¬ MLLMμ„ μƒμ„±ν•λ” λ° InternVL (InternViT-6B)μ„ ν‰κ°€ν•©λ‹λ‹¤. μ΄ ν›λ¥­ν• μ‘μ—…μ— κ°μ‚¬λ“λ¦½λ‹λ‹¤.
λ” μμ„Έν• λ§¤λ‰΄μ–Όλ΅ LLaVA-1.5μ μ›λ λ¬Έμ„λ¥Ό μ μ§€ν–μµλ‹λ‹¤. λ€λ¶€λ¶„μ κ²½μ° μ¶”κ°€λ μƒ λ¬Έμ„λ§ μ°Έμ΅°ν•λ©΄ λ©λ‹λ‹¤.

μ°Έκ³ : μ—¬λ¬ μ‘μ—…μ—μ„ ν™κ²½μ„ ν†µμΌν•κΈ° μ„ν•΄ LLaVA-1.5 μ½”λ“μ— λ‡ κ°€μ§€ νΈν™μ„± μμ •μ„ ν•μ—¬ transformers==4.37.2λ¥Ό μ§€μ›ν•λ„λ΅ ν–μµλ‹λ‹¤ (μ›λλ” 4.31.0μΌλ΅ κ³ μ •λ¨). transformers==4.37.2λ¥Ό μ„¤μΉν•΄μ•Ό ν•©λ‹λ‹¤.

## μ„¤μΉ

λ¨Όμ € μ„¤μΉ κ°€μ΄λ“μ— λ”°λΌ λ‡ κ°€μ§€ κΈ°λ³Έ μ„¤μΉλ¥Ό μν–‰ν•μ‹­μ‹μ¤.

λν• μ΄ μ½”λ“λ² μ΄μ¤λ¥Ό μ‚¬μ©ν•λ ¤λ©΄ λ‹¤μ λ‹¨κ³„λ¥Ό μ‹¤ν–‰ν•΄μ•Ό ν•©λ‹λ‹¤.

λ‹¤λ¥Έ μ”κµ¬ μ‚¬ν•­ μ„¤μΉ:

```bash
pip install --upgrade pip  # PEP 660 μ§€μ› ν™μ„±ν™”
pip install -e .
```

## λ¨λΈ μ¤€λΉ„
| λ¨λΈ μ΄λ¦„ | μ ν• | λ§¤κ°λ³€μ | λ‹¤μ΄λ΅λ“ | ν¬κΈ° |
|---|---|---|---|---|
| InternViT-6B-224px | huggingface | 6B | π¤— HF λ§ν¬ | 12GB |
| InternViT-6B-448px-V1-0 | huggingface | 6B | π¤— HF λ§ν¬ | 12GB |
| vicuna-13b-v1.5 | huggingface | 13B | π¤— HF λ§ν¬ | 13.5GB |
| vicuna-7b-v1.5 | huggingface | 7B | π¤— HF λ§ν¬ | 26.1GB |

μ„μ λ¨λΈ κ°€μ¤‘μΉλ¥Ό λ‹¤μ΄λ΅λ“ν•μ—¬ `pretrained/` ν΄λ”μ— λ„£μΌμ‹­μ‹μ¤.

```bash
cd pretrained/
# pip install -U huggingface_hub
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternViT-6B-224px --local-dir InternViT-6B-224px
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternViT-6B-448px-V1-0 --local-dir InternViT-6B-448px
huggingface-cli download --resume-download --local-dir-use-symlinks False lmsys/vicuna-13b-v1.5 --local-dir vicuna-13b-v1.5
huggingface-cli download --resume-download --local-dir-use-symlinks False lmsys/vicuna-7b-v1.5 --local-dir vicuna-7b-v1.5
```

λ””λ ‰ν† λ¦¬ κµ¬μ΅°λ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

```
pretrained
β”‚β”€β”€ InternViT-6B-224px/
β”‚β”€β”€ InternViT-6B-448px/
β”‚β”€β”€ vicuna-13b-v1.5/
β””β”€β”€ vicuna-7b-v1.5/
```

## ν›λ ¨

**InternViT-6B-224px + Vicuna-7B:**

```bash
# μ‚¬μ „ ν›λ ¨
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/pretrain_internvit6b_224to336_vicuna7b.sh
# λ―Έμ„Έ μ΅°μ •
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/finetune_internvit6b_224to336_vicuna7b.sh
```

**InternViT-6B-224px + Vicuna-13B:**

```bash
# μ‚¬μ „ ν›λ ¨
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/pretrain_internvit6b_224to336_vicuna13b.sh
# λ―Έμ„Έ μ΅°μ •
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/finetune_internvit6b_224to336_vicuna13b.sh
```

**InternViT-6B-448px + Vicuna-7B:**

```bash
# μ‚¬μ „ ν›λ ¨
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/pretrain_internvit6b_448_vicuna7b.sh
# λ―Έμ„Έ μ΅°μ •
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/finetune_internvit6b_448_vicuna7b.sh
```

**InternViT-6B-448px + Vicuna-13B:**

```bash
# μ‚¬μ „ ν›λ ¨
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/pretrain_internvit6b_448_vicuna13b.sh
# λ―Έμ„Έ μ΅°μ •
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh scripts_internvl/finetune_internvit6b_448_vicuna13b.sh
```

## λ¨λΈ μ£Ό(Model Zoo)

| λ°©λ²• | λΉ„μ „ μΈμ½”λ” | LLM | ν•΄μƒλ„ | VQAv2 | GQA | VizWiz | SQA | TextVQA | POPE | MME | MMB | MMB<sub>CN</sub> | MMVet | λ‹¤μ΄λ΅λ“ |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| LLaVA-1.5 | CLIP-L-336px | V-7B | 336 | 78.5 | 62.0 | 50.0 | 66.8 | 58.2 | 85.9 | 1510.7 | 64.3 | 58.3 | 30.5 | π¤— HF λ§ν¬ |
| LLaVA-1.5 | CLIP-L-336px | V-13B | 336 | 80.0 | 63.3 | 53.6 | 71.6 | 61.3 | 85.9 | 1531.3 | 67.7 | 63.6 | 35.4 | π¤— HF λ§ν¬ |
| InternVL-Chat-1.0 | IViT-6B-224px | V-7B | 336 | 79.3 | 62.9 | 52.5 | 66.2 | 57.0 | 86.4 | 1525.1 | 64.6 | 57.6 | 31.2 | π¤— HF λ§ν¬ |
| InternVL-Chat-1.0 | IViT-6B-224px | V-13B | 336 | 80.2 | 63.9 | 54.6 | 70.1 | 58.7 | 87.1 | 1546.9 | 66.5 | 61.9 | 33.7 | π¤— HF λ§ν¬ |
| InternVL-Chat-1.0 | IViT-6B-448px | V-13B | 448 | 82.0 | 64.1 | 60.1 | 71.6 | 64.8 | 87.2 | 1579.0 | 68.2 | 64.0 | 36.7 | π¤— HF λ§ν¬ |

μ„μ λ¨λΈ κ°€μ¤‘μΉλ¥Ό λ‹¤μ΄λ΅λ“ν•μ—¬ `pretrained/` ν΄λ”μ— λ„£μΌμ‹­μ‹μ¤.

```bash
cd pretrained/
# pip install -U huggingface_hub
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-7B --local-dir InternVL-Chat-ViT-6B-Vicuna-7B
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-13B --local-dir InternVL-Chat-ViT-6B-Vicuna-13B
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-13B-448px --local-dir InternVL-Chat-ViT-6B-Vicuna-13B-448px
```

λ””λ ‰ν† λ¦¬ κµ¬μ΅°λ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

```
pretrained
β”‚β”€β”€ InternViT-6B-224px/
β”‚β”€β”€ InternViT-6B-448px/
β”‚β”€β”€ vicuna-13b-v1.5/
β”‚β”€β”€ vicuna-7b-v1.5/
β”‚β”€β”€ InternVL-Chat-ViT-6B-Vicuna-7B/
β”‚β”€β”€ InternVL-Chat-ViT-6B-Vicuna-13B/
β””β”€β”€ InternVL-Chat-ViT-6B-Vicuna-13B-448px/
```

## λ°λ¨

μ›Ή λ°λ¨λ¥Ό λ°°ν¬ν•λ” λ°©λ²•μ€ LLaVA-1.5μ™€ λ™μΌν•©λ‹λ‹¤. λ¨λΈ κ²½λ΅λ§ λ³€κ²½ν•λ©΄ λ©λ‹λ‹¤. κµ¬μ²΄μ μΈ λ‹¨κ³„λ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

**μ»¨νΈλ΅¤λ¬ μ‹μ‘**

```bash
python -m llava.serve.controller --host 0.0.0.0 --port 10000
```

**Gradio μ›Ή μ„λ²„ μ‹μ‘**

```bash
python -m llava.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --port 10038
```

**λ¨λΈ μ›μ»¤ μ‹μ‘**

```bash
# OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-7B
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path ./pretrained/InternVL-Chat-ViT-6B-Vicuna-7B
# OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-13B
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40001 --worker http://localhost:40001 --model-path ./pretrained/InternVL-Chat-ViT-6B-Vicuna-13B
```

μ„ λ‹¨κ³„λ¥Ό μ™„λ£ν• ν›„ http://localhost:10038 μ—μ„ μ›Ή λ°λ¨μ— μ•΅μ„Έμ¤ν•λ©΄ λ‹¤μ νμ΄μ§€λ¥Ό λ³Ό μ μμµλ‹λ‹¤. μ—¬κΈ°μ— λ°°ν¬λ λ¨λΈμ€ InternVL 1.0μ λ‘ λ¨λΈμΈ InternVL-Chat-ViT-6B-Vicuna-7Bμ™€ InternVL-Chat-ViT-6B-Vicuna-13Bμ…λ‹λ‹¤. LLaVA-1.5μ™€μ μ μΌν• μ°¨μ΄μ μ€ CLIP-ViT-300Mμ΄ InternViT-6Bλ΅ λ€μ²΄λμ—λ‹¤λ” κ²ƒμ…λ‹λ‹¤.

λ” ν¨κ³Όμ μΈ MLLMμ΄ ν•„μ”ν•λ©΄ InternVL2 μ‹λ¦¬μ¦ λ¨λΈμ„ ν™•μΈν•μ‹­μ‹μ¤.
λ°λ¨ λ°°ν¬μ— λ€ν• μμ„Έν• λ‚΄μ©μ€ μ—¬κΈ°λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

![alt text](./llava_webui.png)

## ν…μ¤νΈ

λ¨λΈμ„ ν…μ¤νΈν•λ” λ°©λ²•μ€ LLaVA-1.5μ™€ λ™μΌν•©λ‹λ‹¤. μ¤ν¬λ¦½νΈμ κ²½λ΅λ§ λ³€κ²½ν•λ©΄ λ©λ‹λ‹¤. μ¤ν¬λ¦½νΈλ” `scripts_internvl/`μ— μμµλ‹λ‹¤.

μλ¥Ό λ“¤μ–΄ λ‹¨μΌ GPUλ¥Ό μ‚¬μ©ν•μ—¬ MMEλ¥Ό ν…μ¤νΈν•λ ¤λ©΄

```bash
sh scripts_internvl/eval/mme.sh pretrained/InternVL-Chat-ViT-6B-Vicuna-7B/
```

## μΈμ©

μ΄ ν”„λ΅μ νΈκ°€ μ—°κµ¬μ— μ μ©ν•λ‹¤κ³  μƒκ°λλ©΄ λ‹¤μμ„ μΈμ©ν•μ‹­μ‹μ¤.

```
@article{chen2023internvl,
  title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and Li, Bin and Luo, Ping and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}
@article{chen2024far,
  title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}
```

## π‹ LLaVA: λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ μ–΄μ‹μ¤ν„΄νΈ

GPT-4 μμ¤€μ κΈ°λ¥μ„ κ°–μ¶ λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ λ¨λΈμ„ ν–¥ν• μ‹κ°μ  μ§€μΉ¨ νλ‹.

[ν”„λ΅μ νΈ νμ΄μ§€] [λ°λ¨]  [λ°μ΄ν„°] [λ¨λΈ μ£Ό]

π¤μ»¤λ®¤λ‹ν‹° κΈ°μ—¬: [llama.cpp] [Colab] [π¤—Space]

μ‹κ°μ  μ§€μΉ¨ νλ‹μ„ ν†µν• κ°μ„ λ κΈ°μ¤€ [λ…Όλ¬Έ] <br>
Haotian Liu, Chunyuan Li, Yuheng Li, Yong Jae Lee

μ‹κ°μ  μ§€μΉ¨ νλ‹ (NeurIPS 2023, Oral) [λ…Όλ¬Έ]<br>
Haotian Liu*, Chunyuan Li*, Qingyang Wu, Yong Jae Lee (*κ³µλ™ κΈ°μ—¬)

## λ¦΄λ¦¬μ¦

[10/12] π”¥ μ €ν¬ μ—°κµ¬λ¥Ό μ•„λ‚μ—†μ΄ μ§€μ›ν•΄μ£Όμ‹  ETRIμ—μ„ μ μ‘ν• ν•κµ­μ–΄ LLaVA(Ko-LLaVA)λ¥Ό ν™•μΈν•μ„Έμ”! [π¤— λ°λ¨]

[10/12] LLaVAλ” μ΄μ  4λΉ„νΈ/5λΉ„νΈ μ–‘μν™” μ§€μ›μ„ ν†µν•΄ llama.cppμ—μ„ μ§€μ›λ©λ‹λ‹¤!

[10/11] LLaVA-1.5μ ν›λ ¨ λ°μ΄ν„°μ™€ μ¤ν¬λ¦½νΈλ” μ—¬κΈ°μ— λ¦΄λ¦¬μ¦λμ—μΌλ©° ν‰κ°€ μ¤ν¬λ¦½νΈλ” μ—¬κΈ°μ— λ¦΄λ¦¬μ¦λμ—μµλ‹λ‹¤!

[10/5] π”¥ LLaVA-1.5κ°€ μ¶μ‹λμ—μµλ‹λ‹¤! μ›λ LLaVAμ— κ°„λ‹¨ν• μμ •λ§μΌλ΅ 11κ° λ²¤μΉλ§ν¬μ—μ„ SoTAλ¥Ό λ‹¬μ„±ν•κ³ , λ¨λ“  κ³µκ° λ°μ΄ν„°λ¥Ό ν™μ©ν•κ³ , λ‹¨μΌ 8-A100 λ…Έλ“μ—μ„ ~1μΌ λ§μ— ν›λ ¨μ„ μ™„λ£ν•κ³ , μμ‹­μ–µ κ·λ¨μ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•λ” Qwen-VL-Chatκ³Ό κ°™μ€ λ°©λ²•μ„ λ¥κ°€ν•©λ‹λ‹¤. κΈ°μ  λ³΄κ³ μ„λ¥Ό ν™•μΈν•κ³  λ°λ¨λ¥Ό μ‚΄ν΄λ³΄μ„Έμ”! λ¨λΈμ€ λ¨λΈ μ£Όμ—μ„ μ‚¬μ©ν•  μ μμµλ‹λ‹¤.

[9/26] LLaVAλ” μ‚¬μ‹¤ κΈ°λ°μ„ κ°μ„ ν•κ³  ν™κ°μ„ μ¤„μ΄κΈ° μ„ν•΄ μΈκ°„ ν”Όλ“λ°±μ κ°•ν™” ν•™μµ(RLHF)μΌλ΅ κ°μ„ λμ—μµλ‹λ‹¤. ν”„λ΅μ νΈ [LLavA-RLHF]μ—μ„ μƒλ΅μ΄ SFT λ° RLHF μ²΄ν¬ν¬μΈνΈλ¥Ό ν™•μΈν•μ„Έμ”.

[9/22] LLaVAλ” NeurIPS 2023μ—μ„ κµ¬λ‘ λ°ν‘λ΅, LLaVA-Medλ” NeurIPS 2023 λ°μ΄ν„° μ„ΈνΈ λ° λ²¤μΉλ§ν¬ νΈλ™μ—μ„ μ¤ν¬νΈλΌμ΄νΈ λ°ν‘λ΅ μ±„νƒλμ—μµλ‹λ‹¤.

[9/20] 33B λ° 65B LLaVA λ¨λΈ ν›λ ¨μ— λ€ν• μ‹¤μ¦μ  μ—°κµ¬λ¥Ό λ…ΈνΈμ— μ”μ•½ν•©λ‹λ‹¤. λν• λ‹¤μ¤‘ λ¨λ“ κΈ°λ° λ¨λΈμ ν¬κ΄„μ μΈ κ²€ν† , μ§„ν™” λ° μ¶”μ„Έμ— κ΄€μ‹¬μ΄ μλ” κ²½μ° μµκ·Ό μ„¤λ¬Έ μ΅°μ‚¬ λ…Όλ¬Έ "λ‹¤μ¤‘ λ¨λ“ κΈ°λ° λ¨λΈ: μ „λ¬Έκ°€μ—μ„ λ²”μ© λ³΄μ΅°μλ΅"λ¥Ό ν™•μΈν•μ‹­μ‹μ¤.

<p align="center">
<img src="https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings/blob/main/images/mfm_evolution.jpeg?raw=true" width=50%/>
</p>

[7/19] π”¥ LLaMA-2, LoRA ν›λ ¨, 4/8λΉ„νΈ μ¶”λ΅ , κ³ ν•΄μƒλ„(336x336) λ“±μ— λ€ν• μ§€μ›μ„ ν¬ν•¨ν• μ£Όμ” μ—…κ·Έλ μ΄λ“λ¥Ό μ¶μ‹ν•©λ‹λ‹¤. Bard λ° Bing-Chatμ κ²°κ³Όμ™€ ν•¨κ» κ°λ°©ν• μ‹κ° μ±„ν…μ„ λ²¤μΉλ§ν‚Ήν•κΈ° μ„ν• LLaVA λ²¤μΉλ¥Ό μ¶μ‹ν•©λ‹λ‹¤. λν• RTX 3090 λ° RTX A6000μ„ μ‚¬μ©ν• ν›λ ¨μ„ μ§€μ›ν•κ³  κ²€μ¦ν•©λ‹λ‹¤. LLaVA-from-LLaMA-2 λ° λ¨λΈ μ£Όλ¥Ό ν™•μΈν•μ‹­μ‹μ¤!

[6/26] λ€κ·λ¨ λ‹¤μ¤‘ λ¨λ“ λ¨λΈμ— λ€ν• CVPR 2023 νν† λ¦¬μ–Ό: λ‹¤μ¤‘ λ¨λ“ GPT-4 κµ¬μ¶• λ° λ¥κ°€ν•κΈ°! [μ¬λΌμ΄λ“] [λ…ΈνΈ] [YouTube] [Bilibli]λ¥Ό ν™•μΈν•μ‹­μ‹μ¤.

[6/11] κ°€μ¥ λ§μ΄ μ”μ²­λ κΈ°λ¥μ— λ€ν• λ―Έλ¦¬ λ³΄κΈ°μΈ DeepSpeed λ° LoRA μ§€μ›μ„ μ¶μ‹ν–μµλ‹λ‹¤! μμ„Έν• λ‚΄μ©μ€ μ—¬κΈ° λ¬Έμ„λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

[6/1] GPT-4 μμ¤€μ κΈ°λ¥μ„ κ°–μ¶ μƒλ¬Ό μν•™ μμ—­ λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ λ¨λΈμ„ κµ¬μ¶•ν•κΈ° μ„ν• λ‹¨κ³„μΈ LLaVA-Med: μƒλ¬Ό μν•™μ„ μ„ν• λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ λ³΄μ΅°μλ¥Ό μ¶μ‹ν–μµλ‹λ‹¤. λ…Όλ¬Έκ³Ό νμ΄μ§€λ¥Ό ν™•μΈν•μ‹­μ‹μ¤.

[5/6] MPT-7B-Chatμ„ κΈ°λ°μΌλ΅ ν• LLaVA-Lighting-MPT-7B-previewλ¥Ό μ¶μ‹ν•©λ‹λ‹¤! μμ„Έν• λ‚΄μ©μ€ μ—¬κΈ°λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

[5/2] π”¥ λ‹¨ 3μ‹κ°„ λ§μ— 40λ‹¬λ¬λ΅ λΌμ΄νΈν• λ‹¤μ¤‘ λ¨λ“ GPT-4λ¥Ό ν›λ ¨ν•λ” LLaVA-Lightingμ„ μ¶μ‹ν•©λ‹λ‹¤! μμ„Έν• λ‚΄μ©μ€ μ—¬κΈ°λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

[4/27] μ»¤λ®¤λ‹ν‹° λ…Έλ ¥ λ•λ¶„μ— 4λΉ„νΈ μ–‘μν™”λ¥Ό μ‚¬μ©ν• LLaVA-13Bλ¥Ό μ‚¬μ©ν•λ©΄ 12GB VRAMλ§ μλ” GPUμ—μ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤! μ—¬κΈ°μ„ μ‹λ„ν•΄ λ³΄μ‹­μ‹μ¤.

[4/17] π”¥ GPT-4 μμ¤€μ κΈ°λ¥μ„ κ°–μ¶ λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ λ¨λΈμ„ κµ¬μ¶•ν•κΈ° μ„ν• μ‹κ°μ  μ§€μΉ¨ νλ‹μΈ LLaVA: λ€κ·λ¨ μ–Έμ–΄ λ° λΉ„μ „ λ³΄μ΅°μλ¥Ό μ¶μ‹ν–μµλ‹λ‹¤. λ…Όλ¬Έκ³Ό λ°λ¨λ¥Ό ν™•μΈν•μ‹­μ‹μ¤.

<!-- <a href="https://llava.hliu.cc/"><img src="assets/demo.gif" width="70%"></a> -->

![alt text](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)

![alt text](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)

μ‚¬μ© λ° λΌμ΄μ„ μ¤ κ³ μ§€: λ°μ΄ν„°μ™€ μ²΄ν¬ν¬μΈνΈλ” μ—°κµ¬μ©μΌλ΅λ§ μ‚¬μ©ν•λ„λ΅ ν—κ°€λμ—μµλ‹λ‹¤. λν• LLaMA, Vicuna λ° GPT-4μ λΌμ΄μ„ μ¤ κ³„μ•½μ„ λ”°λ¥΄λ” μ©λ„λ΅ μ ν•λ©λ‹λ‹¤. λ°μ΄ν„° μ„ΈνΈλ” CC BY NC 4.0(λΉ„μƒμ—…μ  μ©λ„λ΅λ§ ν—μ©λ¨)μ΄λ©° λ°μ΄ν„° μ„ΈνΈλ¥Ό μ‚¬μ©ν•μ—¬ ν›λ ¨λ λ¨λΈμ€ μ—°κµ¬ λ©μ  μ΄μ™Έμ μ©λ„λ΅ μ‚¬μ©ν•΄μ„λ” μ• λ©λ‹λ‹¤.

## λ©μ°¨

- μ„¤μΉ
- LLaVA κ°€μ¤‘μΉ
- λ°λ¨
- λ¨λΈ μ£Ό
- λ°μ΄ν„° μ„ΈνΈ
- ν›λ ¨
- ν‰κ°€

## μ„¤μΉ

μ΄ μ €μ¥μ†λ¥Ό λ³µμ ν•κ³  LLaVA ν΄λ”λ΅ μ΄λ™ν•©λ‹λ‹¤.

```bash
git clone https://github.com/haotian-liu/LLaVA.git
cd LLaVA
```

ν¨ν‚¤μ§€ μ„¤μΉ

```bash
conda create -n llava python=3.10 -y
conda activate llava
pip install --upgrade pip  # PEP 660 μ§€μ› ν™μ„±ν™”
pip install -e .
```

ν›λ ¨ μ‚¬λ΅€μ— λ€ν• μ¶”κ°€ ν¨ν‚¤μ§€ μ„¤μΉ

```bash
pip install ninja
pip install flash-attn --no-build-isolation
```

μµμ‹  μ½”λ“ λ² μ΄μ¤λ΅ μ—…κ·Έλ μ΄λ“
```bash
git pull
pip uninstall transformers
pip install -e .
```

## LLaVA κ°€μ¤‘μΉ

λ¨λ“  κ³µκ° LLaVA μ²΄ν¬ν¬μΈνΈμ™€ κ°€μ¤‘μΉ μ‚¬μ© λ°©λ²•μ— λ€ν• μ§€μΉ¨μ€ λ¨λΈ μ£Όλ¥Ό ν™•μΈν•μ‹­μ‹μ¤.

## λ°λ¨

λ°λ¨λ¥Ό μ‹¤ν–‰ν•λ ¤λ©΄ LLaVA μ²΄ν¬ν¬μΈνΈλ¥Ό λ΅μ»¬λ΅ μ¤€λΉ„ν•΄μ•Ό ν•©λ‹λ‹¤. μ—¬κΈ°μ— μλ” μ§€μΉ¨μ— λ”°λΌ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ν•μ‹­μ‹μ¤.

### Gradio μ›Ή UI

Gradio λ°λ¨λ¥Ό λ΅μ»¬λ΅ μ‹μ‘ν•λ ¤λ©΄ λ‹¤μ λ…λ Ήμ„ ν•λ‚μ”© μ‹¤ν–‰ν•μ‹­μ‹μ¤. μ—¬λ¬ λ¨λΈ μ‘μ—…μλ¥Ό μ‹μ‘ν•μ—¬ λ‹¤λ¥Έ μ²΄ν¬ν¬μΈνΈ κ°„μ„ λΉ„κµν•λ ¤λ” κ²½μ° μ»¨νΈλ΅¤λ¬μ™€ μ›Ή μ„λ²„λ¥Ό ν• λ²λ§ μ‹μ‘ν•λ©΄ λ©λ‹λ‹¤.

```bash
python -m llava.serve.controller --host 0.0.0.0 --port 10000
```

```bash
python -m llava.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload
```

μ΄μ  Gradio μ›Ή μΈν„°νμ΄μ¤λ¥Ό μ‹μ‘ν–μµλ‹λ‹¤. μ΄μ  ν™”λ©΄μ— μΈμ‡„λ URLλ΅ μ›Ή μΈν„°νμ΄μ¤λ¥Ό μ—΄ μ μμµλ‹λ‹¤. λ¨λΈ λ©λ΅μ— λ¨λΈμ΄ μ—†λ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤. κ±±μ •ν•μ§€ λ§μ‹­μ‹μ¤. μ•„μ§ λ¨λΈ μ‘μ—…μλ¥Ό μ‹μ‘ν•μ§€ μ•μ•κΈ° λ•λ¬Έμ…λ‹λ‹¤. λ¨λΈ μ‘μ—…μλ¥Ό μ‹μ‘ν•λ©΄ μλ™μΌλ΅ μ—…λ°μ΄νΈλ©λ‹λ‹¤.

μ΄κ²ƒμ€ GPUμ—μ„ μ¶”λ΅ μ„ μν–‰ν•λ” μ‹¤μ  μ‘μ—…μμ…λ‹λ‹¤. κ° μ‘μ—…μλ” --model-pathμ— μ§€μ •λ λ‹¨μΌ λ¨λΈμ„ λ‹΄λ‹Ήν•©λ‹λ‹¤.

```bash
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path liuhaotian/llava-v1.5-13b
```

ν”„λ΅μ„Έμ¤κ°€ λ¨λΈ λ΅λ“λ¥Ό μ™„λ£ν•κ³  "Uvicorn running on ..."μ΄ ν‘μ‹λ  λ•κΉμ§€ κΈ°λ‹¤λ¦½λ‹λ‹¤. μ΄μ  Gradio μ›Ή UIλ¥Ό μƒλ΅ κ³ μΉλ©΄ λ°©κΈ μ‹μ‘ν• λ¨λΈμ΄ λ¨λΈ λ©λ΅μ— ν‘μ‹λ©λ‹λ‹¤.

μ›ν•λ” λ§νΌ μ‘μ—…μλ¥Ό μ‹μ‘ν•κ³  λ™μΌν• Gradio μΈν„°νμ΄μ¤μ—μ„ λ‹¤λ¥Έ λ¨λΈ μ²΄ν¬ν¬μΈνΈ κ°„μ„ λΉ„κµν•  μ μμµλ‹λ‹¤. --controllerλ” λ™μΌν•κ² μ μ§€ν•κ³  κ° μ‘μ—…μμ— λ€ν•΄ --port λ° --workerλ¥Ό λ‹¤λ¥Έ ν¬νΈ λ²νΈλ΅ μμ •ν•μ‹­μ‹μ¤.

```bash
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port <40000κ³Ό λ‹¤λ¦„, μλ¥Ό λ“¤μ–΄ 40001> --worker http://localhost:<μ΄μ— λ”°λΌ λ³€κ²½, μ: 40001> --model-path <ckpt2>
```

M1 λλ” M2 μΉ©μ΄ μ¥μ°©λ Apple μ¥μΉλ¥Ό μ‚¬μ©ν•λ” κ²½μ° --device ν”λκ·Έ: --device mpsλ¥Ό μ‚¬μ©ν•μ—¬ mps μ¥μΉλ¥Ό μ§€μ •ν•  μ μμµλ‹λ‹¤.

GPUμ VRAMμ΄ 24GB λ―Έλ§(μ: RTX 3090, RTX 4090 λ“±)μΈ κ²½μ° μ—¬λ¬ GPUλ΅ μ‹¤ν–‰ν•΄ λ³Ό μ μμµλ‹λ‹¤. μµμ‹  μ½”λ“ λ² μ΄μ¤λ” GPUκ°€ λ‘ κ° μ΄μƒ μλ” κ²½μ° μλ™μΌλ΅ μ—¬λ¬ GPUλ¥Ό μ‚¬μ©ν•λ ¤κ³  μ‹λ„ν•©λ‹λ‹¤. CUDA_VISIBLE_DEVICESλ΅ μ‚¬μ©ν•  GPUλ¥Ό μ§€μ •ν•  μ μμµλ‹λ‹¤. λ‹¤μμ€ μ²μ λ‘ GPUλ΅ μ‹¤ν–‰ν•λ” μμ…λ‹λ‹¤.

```bash
CUDA_VISIBLE_DEVICES=0,1 python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path liuhaotian/llava-v1.5-13b
```

μ–‘μν™”λ λΉ„νΈ(4λΉ„νΈ, 8λΉ„νΈ)λ΅ λ¨λΈ μ‘μ—…μλ¥Ό μ‹μ‘ν•  μ μμΌλ©°, μ΄λ¥Ό ν†µν•΄ GPU λ©”λ¨λ¦¬ μ‚¬μ© κ³µκ°„μ„ μ¤„μ—¬ μ¶”λ΅ μ„ μ‹¤ν–‰ν•  μ μμΌλ―€λ΅ 12GB VRAMλ§ μλ” GPUμ—μ„λ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤. μ–‘μν™”λ λΉ„νΈλ¥Ό μ‚¬μ©ν• μ¶”λ΅ μ€ μ „μ²΄ μ •λ°€λ„ λ¨λΈλ§νΌ μ •ν™•ν•μ§€ μ•μ„ μ μμµλ‹λ‹¤. μ‹¤ν–‰ μ¤‘μΈ λ¨λΈ μ‘μ—…μ λ…λ Ήμ— --load-4bit λλ” --load-8bitλ¥Ό μ¶”κ°€ν•κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤. λ‹¤μμ€ 4λΉ„νΈ μ–‘μν™”λ΅ μ‹¤ν–‰ν•λ” μμ…λ‹λ‹¤.

```bash
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path liuhaotian/llava-v1.5-13b --load-4bit
```

λ””μ¤ν¬ κ³µκ°„μ„ μ μ•½ν•κΈ° μ„ν•΄ κΈ°λ³Έ μ²΄ν¬ν¬μΈνΈμ™€ λ³‘ν•©ν•μ§€ μ•κ³  LoRA κ°€μ¤‘μΉλ΅ λ¨λΈ μ‘μ—…μλ¥Ό μ‹μ‘ν•  μ μμµλ‹λ‹¤. μ¶”κ°€ λ΅λ“ μ‹κ°„μ΄ μμ§€λ§ μ¶”λ΅  μ†λ„λ” λ³‘ν•©λ μ²΄ν¬ν¬μΈνΈμ™€ λ™μΌν•©λ‹λ‹¤. λ³‘ν•©λμ§€ μ•μ€ LoRA μ²΄ν¬ν¬μΈνΈλ” λ¨λΈ μ΄λ¦„μ— lora-mergeκ°€ μ—†μΌλ©° μΌλ°μ μΌλ΅ λ³‘ν•©λ μ²΄ν¬ν¬μΈνΈ(7Bμ κ²½μ° 13G, 13Bμ κ²½μ° 25G)λ³΄λ‹¤ ν›¨μ”¬ μ‘μµλ‹λ‹¤(1GB λ―Έλ§).

λ³‘ν•©λμ§€ μ•μ€ LoRA κ°€μ¤‘μΉλ¥Ό λ΅λ“ν•λ ¤λ©΄ LoRA κ°€μ¤‘μΉλ¥Ό ν›λ ¨ν•λ” λ° μ‚¬μ©λλ” κΈ°λ³Έ LLMμΈ --model-baseλΌλ” μ¶”κ°€ μΈμλ¥Ό μ „λ‹¬ν•κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤. κ° LoRA κ°€μ¤‘μΉμ κΈ°λ³Έ LLMμ€ λ¨λΈ μ£Όμ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

```bash
python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path liuhaotian/llava-v1-0719-336px-lora-vicuna-13b-v1.3 --model-base lmsys/vicuna-13b-v1.3
```

### CLI μ¶”λ΅ 

Gradio μΈν„°νμ΄μ¤ μ—†μ΄ LLaVAλ¥Ό μ‚¬μ©ν•μ—¬ μ΄λ―Έμ§€μ— λ€ν•΄ μ±„ν…ν•©λ‹λ‹¤. λν• μ—¬λ¬ GPU, 4λΉ„νΈ λ° 8λΉ„νΈ μ–‘μν™” μ¶”λ΅ μ„ μ§€μ›ν•©λ‹λ‹¤. 4λΉ„νΈ μ–‘μν™”λ¥Ό μ‚¬μ©ν•λ©΄ LLaVA-1.5-7Bμ κ²½μ° λ‹¨μΌ GPUμ—μ„ 8GB λ―Έλ§μ VRAMμ„ μ‚¬μ©ν•©λ‹λ‹¤.

```bash
python -m llava.serve.cli \
    --model-path liuhaotian/llava-v1.5-7b \
    --image-file "https://llava-vl.github.io/static/images/view.jpg" \
    --load-4bit
```

## ν›λ ¨

λ‹¤μμ€ LLaVA v1.5μ— λ€ν• μµμ‹  ν›λ ¨ κµ¬μ„±μ…λ‹λ‹¤. λ κ±°μ‹ λ¨λΈμ κ²½μ° ν„μ¬ λ²„μ „μ READMEλ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤. λ‚μ¤‘μ— λ³„λ„μ λ¬Έμ„μ— μ¶”κ°€ν•  μμ •μ…λ‹λ‹¤.

LLaVA ν›λ ¨μ€ λ‘ λ‹¨κ³„λ΅ κµ¬μ„±λ©λ‹λ‹¤. (1) κΈ°λ¥ μ •λ ¬ λ‹¨κ³„: LAION-CC-SBU λ°μ΄ν„° μ„ΈνΈμ 558K ν•μ„ μ§‘ν•©μ„ μ‚¬μ©ν•μ—¬ κ³ μ •λ μ‚¬μ „ ν›λ ¨λ λΉ„μ „ μΈμ½”λ”λ¥Ό κ³ μ •λ LLMμ— μ—°κ²°ν•©λ‹λ‹¤. (2) μ‹κ°μ  μ§€μΉ¨ νλ‹ λ‹¨κ³„: 150K GPT μƒμ„± λ‹¤μ¤‘ λ¨λ“ μ§€μΉ¨ μ¤€μ λ°μ΄ν„°μ™€ ν•™μ  μ§€ν–¥ μ‘μ—…μ μ•½ 515K VQA λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬ λ¨λΈμ΄ λ‹¤μ¤‘ λ¨λ“ μ§€μΉ¨μ„ λ”°λ¥΄λ„λ΅ ν›λ ¨ν•©λ‹λ‹¤.

LLaVAλ” 80GB λ©”λ¨λ¦¬κ°€ μλ” 8κ°μ A100 GPUμ—μ„ ν›λ ¨λ©λ‹λ‹¤. λ” μ μ€ GPUμ—μ„ ν›λ ¨ν•λ ¤λ©΄ per_device_train_batch_sizeλ¥Ό μ¤„μ΄κ³  gradient_accumulation_stepsλ¥Ό κ·Έμ— λ”°λΌ λλ¦΄ μ μμµλ‹λ‹¤. ν•­μƒ κΈ€λ΅λ² λ°°μΉ ν¬κΈ°λ¥Ό λ™μΌν•κ² μ μ§€ν•μ‹­μ‹μ¤. per_device_train_batch_size x gradient_accumulation_steps x num_gpus.

### ν•μ΄νΌνλΌλ―Έν„°

λ―Έμ„Έ μ΅°μ •μ—μ„ Vicunaμ™€ μ μ‚¬ν• ν•μ΄νΌνλΌλ―Έν„° μ§‘ν•©μ„ μ‚¬μ©ν•©λ‹λ‹¤. μ‚¬μ „ ν›λ ¨κ³Ό λ―Έμ„Έ μ΅°μ •μ— μ‚¬μ©λλ” ν•μ΄νΌνλΌλ―Έν„°λ” μ•„λμ— μ κ³µλ©λ‹λ‹¤.

#### μ‚¬μ „ ν›λ ¨

| ν•μ΄νΌνλΌλ―Έν„° | κΈ€λ΅λ² λ°°μΉ ν¬κΈ° | ν•™μµλ¥  | μ—ν¬ν¬ | μµλ€ κΈΈμ΄ | κ°€μ¤‘μΉ κ°μ‡  |
|---|---|---|---|---|---|
| LLaVA-v1.5-13B | 256 | 1e-3 | 1 | 2048 | 0 |

#### λ―Έμ„Έ μ΅°μ •

| ν•μ΄νΌνλΌλ―Έν„° | κΈ€λ΅λ² λ°°μΉ ν¬κΈ° | ν•™μµλ¥  | μ—ν¬ν¬ | μµλ€ κΈΈμ΄ | κ°€μ¤‘μΉ κ°μ‡  |
|---|---|---|---|---|---|
| LLaVA-v1.5-13B | 128 | 2e-5 | 1 | 2048 | 0 |

### Vicuna μ²΄ν¬ν¬μΈνΈ λ‹¤μ΄λ΅λ“(μλ™)

μ§€μΉ¨ νλ‹λ μ±—λ΄‡μΈ κΈ°λ³Έ λ¨λΈ Vicuna v1.5λ” μ κ³µλ ν›λ ¨ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•  λ• μλ™μΌλ΅ λ‹¤μ΄λ΅λ“λ©λ‹λ‹¤. μ΅°μΉκ°€ ν•„μ”ν•μ§€ μ•μµλ‹λ‹¤.

### μ‚¬μ „ ν›λ ¨(κΈ°λ¥ μ •λ ¬)

μ—¬κΈ°μ— μλ” λ…Όλ¬Έμ—μ„ μ‚¬μ©ν•λ” BLIP μΊ΅μ…μ΄ μλ” LAION-CC-SBU λ°μ΄ν„° μ„ΈνΈμ 558K ν•μ„ μ§‘ν•©μ„ λ‹¤μ΄λ΅λ“ν•μ‹­μ‹μ¤.

μ‚¬μ „ ν›λ ¨μ€ ν•΄μƒλ„κ°€ 336pxλ΅ μ¦κ°€ν–κΈ° λ•λ¬Έμ— 8x A100(80G)μ—μ„ LLaVA-v1.5-13Bμ κ²½μ° μ•½ 5.5μ‹κ°„μ΄ μ†μ”λ©λ‹λ‹¤. LLaVA-v1.5-7Bμ κ²½μ° μ•½ 3.5μ‹κ°„μ΄ μ†μ”λ©λ‹λ‹¤.

DeepSpeed ZeRO-2λ¥Ό μ‚¬μ©ν• ν›λ ¨ μ¤ν¬λ¦½νΈ: pretrain.sh.

- --mm_projector_type mlp2x_gelu: 2κ³„μΈµ MLP λΉ„μ „-μ–Έμ–΄ μ»¤λ„¥ν„°.
- --vision_tower openai/clip-vit-large-patch14-336: CLIP ViT-L/14 336px.

### μ‹κ°μ  μ§€μΉ¨ νλ‹

#### λ°μ΄ν„° μ¤€λΉ„

μµμΆ… νΌν•© μ§€μΉ¨ νλ‹ λ°μ΄ν„° llava_v1_5_mix665k.jsonμ μ£Όμ„μ„ λ‹¤μ΄λ΅λ“ν•κ³  κµ¬μ„± λ°μ΄ν„° μ„ΈνΈμ—μ„ μ΄λ―Έμ§€λ¥Ό λ‹¤μ΄λ΅λ“ν•μ‹­μ‹μ¤.

- COCO: train2017
- GQA: images
- OCR-VQA: download script
- TextVQA: train_val_images
- VisualGenome: part1, part2

λ¨λ‘ λ‹¤μ΄λ΅λ“ν• ν›„ ./playground/dataμ— λ‹¤μκ³Ό κ°™μ΄ λ°μ΄ν„°λ¥Ό κµ¬μ„±ν•μ‹­μ‹μ¤.

```
β”β”€β”€ coco
β”‚   β””β”€β”€ train2017
β”β”€β”€ gqa
β”‚   β””β”€β”€ images
β”β”€β”€ ocr_vqa
β”‚   β””β”€β”€ images
β”β”€β”€ textvqa
β”‚   β””β”€β”€ train_images
β””β”€β”€ vg
    β”β”€β”€ VG_100K
    β””β”€β”€ VG_100K_2
```

#### ν›λ ¨ μ‹μ‘!

λ¨λΈ μ£Όμ—μ„ μ‚¬μ „ ν›λ ¨λ ν”„λ΅μ ν„°λ¥Ό λ‹¤μ΄λ΅λ“ν•  μ μμµλ‹λ‹¤. λ κ±°μ‹ ν”„λ΅μ ν„°λ¥Ό μ‚¬μ©ν•λ” κ²ƒμ€ κ¶μ¥λμ§€ μ•μµλ‹λ‹¤. μ½”λ“ λ² μ΄μ¤μ λ‹¤λ¥Έ λ²„μ „μΌλ΅ ν›λ ¨λμ—μ„ μ μμΌλ©° μµμ…μ΄ κΊΌμ Έ μμΌλ©΄ λ¨λΈμ΄ μμƒλ€λ΅ μ‘λ™/ν›λ ¨λμ§€ μ•κΈ° λ•λ¬Έμ…λ‹λ‹¤.

μ‹κ°μ  μ§€μΉ¨ νλ‹μ€ ν•΄μƒλ„κ°€ 336pxλ΅ μ¦κ°€ν–κΈ° λ•λ¬Έμ— 8x A100(80G)μ—μ„ LLaVA-v1.5-13Bμ κ²½μ° μ•½ 20μ‹κ°„μ΄ μ†μ”λ©λ‹λ‹¤. 8x A100(40G)μ—μ„ LLaVA-v1.5-7Bμ κ²½μ° μ•½ 10μ‹κ°„μ΄ μ†μ”λ©λ‹λ‹¤.

DeepSpeed ZeRO-3λ¥Ό μ‚¬μ©ν• ν›λ ¨ μ¤ν¬λ¦½νΈ: finetune.sh.

μ°Έκ³ ν•  μƒλ΅μ΄ μµμ…:

- --mm_projector_type mlp2x_gelu: 2κ³„μΈµ MLP λΉ„μ „-μ–Έμ–΄ μ»¤λ„¥ν„°.
- --vision_tower openai/clip-vit-large-patch14-336: CLIP ViT-L/14 336px.
- --image_aspect_ratio pad: μ •μ‚¬κ°ν•μ΄ μ•„λ‹ μ΄λ―Έμ§€λ¥Ό μλ¥΄λ” λ€μ‹  μ •μ‚¬κ°ν•μΌλ΅ μ±„μ›λ‹λ‹¤. ν™κ°μ„ μ•½κ°„ μ¤„μ…λ‹λ‹¤.
- --group_by_modality_length True: μ§€μΉ¨ νλ‹ λ°μ΄ν„° μ„ΈνΈμ— μ–Έμ–΄(μ: ShareGPT)μ™€ λ‹¤μ¤‘ λ¨λ“(μ: LLaVA-Instruct)κ°€ λ¨λ‘ ν¬ν•¨λ κ²½μ°μ—λ§ μ‚¬μ©ν•΄μ•Ό ν•©λ‹λ‹¤. ν›λ ¨ μƒν”λ¬κ°€ ν›λ ¨ μ¤‘μ— λ‹¨μΌ μ–‘μ‹(μ΄λ―Έμ§€ λλ” μ–Έμ–΄)λ§ μƒν”λ§ν•λ„λ΅ ν•μ—¬ ν›λ ¨ μ†λ„λ¥Ό ~25% λ†’μ΄κ³  μµμΆ… κ²°κ³Όμ— μν–¥μ„ λ―ΈμΉμ§€ μ•μµλ‹λ‹¤.

## ν‰κ°€

LLaVA-1.5μ—μ„λ” 12κ°μ λ‹¤μ–‘ν• λ²¤μΉλ§ν¬μ—μ„ λ¨λΈμ„ ν‰κ°€ν•©λ‹λ‹¤. μ¬ν„μ„±μ„ λ³΄μ¥ν•κΈ° μ„ν•΄ νƒμ•μ  λ””μ½”λ”©μΌλ΅ λ¨λΈμ„ ν‰κ°€ν•©λ‹λ‹¤. μ‹¤μ‹κ°„ μ¶λ ¥μ μ±„ν… λ°λ¨μ™€ μ¶”λ΅  ν”„λ΅μ„Έμ¤λ¥Ό μΌκ΄€λκ² μ μ§€ν•κΈ° μ„ν•΄ λΉ” κ²€μƒ‰μ„ μ‚¬μ©ν•μ—¬ ν‰κ°€ν•μ§€ μ•μµλ‹λ‹¤.

Evaluation.mdλ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

### GPT μ§€μ› ν‰κ°€

λ‹¤μ¤‘ λ¨λ“ λ¨λΈλ§μ„ μ„ν• GPT μ§€μ› ν‰κ°€ νμ΄ν”„λΌμΈμ€ λΉ„μ „-μ–Έμ–΄ λ¨λΈμ κΈ°λ¥μ— λ€ν• ν¬κ΄„μ μΈ μ΄ν•΄λ¥Ό μ„ν•΄ μ κ³µλ©λ‹λ‹¤. μμ„Έν• λ‚΄μ©μ€ λ…Όλ¬Έμ„ μ°Έμ΅°ν•μ‹­μ‹μ¤.

#### LLaVA μ‘λ‹µ μƒμ„±

```bash
python model_vqa.py \
    --model-path ./checkpoints/LLaVA-13B-v0 \
    --question-file \
    playground/data/coco2014_val_qa_eval/qa90_questions.jsonl \
    --image-folder \
    /path/to/coco2014_val \
    --answers-file \
    /path/to/answer-file-our.jsonl
```

μƒμ„±λ μ‘λ‹µμ„ ν‰κ°€ν•©λ‹λ‹¤. μ΄ κ²½μ° answer-file-ref.jsonlμ€ μ»¨ν…μ¤νΈ μΊ΅μ…/μƒμκ°€ μ κ³µλ ν…μ¤νΈ μ „μ© GPT-4(0314)μ—μ„ μƒμ„±λ μ‘λ‹µμ…λ‹λ‹¤.

```bash
OPENAI_API_KEY="sk-***********************************" python llava/eval/eval_gpt_review_visual.py \
    --question playground/data/coco2014_val_qa_eval/qa90_questions.jsonl \
    --context llava/eval/table/caps_boxes_coco2014_val_80.jsonl \
    --answer-list \
    /path/to/answer-file-ref.jsonl \
    /path/to/answer-file-our.jsonl \
    --rule llava/eval/table/rule.json \
    --output /path/to/review.json
```

ν‰κ°€ κ²°κ³Ό μ”μ•½

```bash
python summarize_gpt_review.py
```

## μΈμ©

LLaVAκ°€ μ—°κµ¬ λ° μ‘μ© ν”„λ΅κ·Έλ¨μ— μ μ©ν•λ‹¤κ³  μƒκ°λλ©΄ λ‹¤μ BibTeXλ¥Ό μ‚¬μ©ν•μ—¬ μΈμ©ν•μ‹­μ‹μ¤.

```
@misc{liu2023improvedllava,
      title={Improved Baselines with Visual Instruction Tuning},
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}

@misc{liu2023llava,
      title={Visual Instruction Tuning},
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      publisher={arXiv:2304.08485},
      year={2023},
}
```

## κ°μ‚¬μ λ§

- Vicuna: μ°λ¦¬κ°€ κΈ°λ°μΌλ΅ ν• μ½”λ“λ² μ΄μ¤μ΄μ λ†€λΌμ΄ μ–Έμ–΄ κΈ°λ¥μ„ κ°–μ¶ κΈ°λ³Έ λ¨λΈ Vicuna-13B!

### Related Projects

- [Instruction Tuning with GPT-4](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)
- [LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day](https://github.com/microsoft/LLaVA-Med)
- [Otter: In-Context Multi-Modal Instruction Tuning](https://github.com/Luodian/Otter)

For future project ideas, please check out:

- [SEEM: Segment Everything Everywhere All at Once](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)
- [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) to detect, segment, and generate anything by marrying [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO) and [Segment-Anything](https://github.com/facebookresearch/segment-anything).

<br>
<br>
